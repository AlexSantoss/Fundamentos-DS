{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import groupby\n",
    "from os import listdir, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b1faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formata_data_hora(mi):\n",
    "    #troca / por - e remove 'UTC' das strings de hora\n",
    "    data, hora = mi[0].replace('/', '-'), mi[1].replace(' UTC', '')\n",
    "    if len(hora) == 4:  hora = hora[:2] + ':' + hora[2:]\n",
    "    return data, hora\n",
    "\n",
    "def ler_arquivo(arquivo):\n",
    "    #lendo o arquivo em duas partes\n",
    "    metadado = pd.read_csv(arquivo, encoding='latin_1', sep=';', decimal=',', nrows=8, header=None).set_index(0)\n",
    "    dados = pd.read_csv(arquivo, skiprows=8, encoding='latin_1', sep=';', decimal=',').replace(-9999, np.nan)\n",
    "    \n",
    "    #removendo o : dos nomes dos metadados e normalizando as que variam com o tempo\n",
    "    metadado.index = ['REGIÃO', 'UF', 'ESTAÇÃO', 'CODIGO (WMO)', 'LATITUDE', 'LONGITUDE', 'ALTITUDE', 'DATA DE FUNDAÇÃO (YYYY-MM-DD)']\n",
    "    metadado = metadado.T.iloc[0]\n",
    "    \n",
    "    #acrescentando os dados de altitude, latitude e longitudo no dataframe (podem mudar de ano a ano)\n",
    "    dados.assign(**{\n",
    "        'ALTITUDE': metadado['ALTITUDE'],\n",
    "        'LATITUDE': metadado['LATITUDE'],\n",
    "        'LONGITUDE': metadado['LONGITUDE']\n",
    "    })\n",
    "    \n",
    "    #normalizando nomes de colunas que mudam na planilha\n",
    "    dados.rename({\n",
    "        dados.columns[0]: 'Data',\n",
    "        dados.columns[1]: 'Hora',\n",
    "        dados.columns[6]: 'RADIACAO GLOBAL (KJ/m²)'\n",
    "    }, axis='columns', inplace=True)\n",
    "    \n",
    "    #retornando o codigo da estaçao, dicionario com a regiao, uf e nome da estação, dataframe com todos os dados\n",
    "    return metadado['CODIGO (WMO)'], metadado[['REGIÃO', 'UF', 'ESTAÇÃO']].to_dict(), dados.set_index(list(dados.columns[:2]))\n",
    "\n",
    "def concat_years(code, file_list, output_dir):\n",
    "    #faz a leitura de cada arquivo\n",
    "    years = []\n",
    "    for file in sorted(file_list):\n",
    "        _, metadata, dataframe = ler_arquivo(file)\n",
    "        years.append(dataframe)\n",
    "    \n",
    "    #concatena e arruma o index\n",
    "    df = pd.concat(years, copy=False)\n",
    "    df.index = df.index.map(formata_data_hora)\n",
    "        \n",
    "    #salva o arquivo concatenado e retorna os metadados\n",
    "    name = f'{metadata[\"REGIÃO\"]}_{metadata[\"UF\"]}_{code}_{metadata[\"ESTAÇÃO\"]}'\n",
    "    df.sort_index().to_csv(f'{output_dir}/{name}.csv', sep=';', decimal=',', encoding='latin_1')\n",
    "\n",
    "def padronize_data(inmet_dir, output_dir):\n",
    "    #salvando o nome de todas as planilhas\n",
    "    arquivos = []\n",
    "    for folder in listdir(inmet_dir):\n",
    "        c = f'{inmet_dir}/{folder}'\n",
    "        if not path.isdir(c): continue\n",
    "        if path.isdir(f'{c}/{folder}'): c = f'{c}/{folder}'\n",
    "        arquivos += [f'{c}/{a}' for a in listdir(c) if a.endswith('.CSV')]\n",
    "    print(f'Total de arquivos: {len(arquivos)}')\n",
    "    \n",
    "    #para cada codigo, concatena e adiciona o codigo e salva os metadados\n",
    "    metadatas = []\n",
    "    search_groups = lambda s: re.search('_([A-Z][0-9]{3})_', s).group(1)\n",
    "    for k, grupo in groupby(sorted(arquivos, key=search_groups), search_groups):\n",
    "        print(f'Codigo {k}...', end='')\n",
    "        concat_years(k, grupo, output_dir)\n",
    "        print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a9e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_inmet = 'datasets/inmet'\n",
    "path_output = 'datasets/agregados'\n",
    "padronize_data(path_inmet, path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: adaptar para os novos formatos\n",
    "def resumo(arquivo):\n",
    "    metadado = pd.read_csv(arquivo, encoding='latin_1', sep=';', decimal=',', nrows=8, header=None)\n",
    "    local = f'{metadado.iloc[0, 1]} -- {metadado.iloc[1, 1]} -- {metadado.iloc[3,1]} -- {metadado.iloc[2,1]}'\n",
    "    \n",
    "    dados = pd.read_csv(arquivo, skiprows=8, encoding='latin_1', sep=';', decimal=',').replace(-9999, np.nan)\n",
    "    return dados.min().rename(local), dados.max().rename(local), (dados.isnull().sum(axis=0)/len(dados)*100).rename(local), dados.apply(lambda x: x.groupby(x.notna().cumsum()).cumcount().max()).rename(local)\n",
    "\n",
    "def resumo_anual(ano):\n",
    "    tabelas = {\n",
    "        'min': [], #minimo de cada coluna\n",
    "        'max': [], #maximo de cada coluna\n",
    "        'porcentagem': [], #porcentagem de nulos em cada coluna\n",
    "        'sequencia': []  #maior sequencia de nulos\n",
    "    }\n",
    "    \n",
    "    d = f'{p}/{ano}/'\n",
    "    if path.isdir(f'{d}{ano}'): d = f'{d}{ano}/'\n",
    "        \n",
    "    for file in listdir(d):\n",
    "        minimo, maximo, porcentagem, sequencia = resumo(d+file)\n",
    "        tabelas['min'].append(minimo)\n",
    "        tabelas['max'].append(maximo)\n",
    "        tabelas['porcentagem'].append(porcentagem)\n",
    "        tabelas['sequencia'].append(sequencia)\n",
    "    \n",
    "    for k, v in tabelas.items():\n",
    "        df = pd.DataFrame(v)\n",
    "        df.columns = [f'{k.upper()} - {c}' for c in df.columns]\n",
    "        tabelas[k] = df\n",
    "        \n",
    "    colunas = [v.columns for k, v in tabelas.items()]\n",
    "    colunas = [j for i in zip(*colunas) for j in i]\n",
    "    return pd.concat(tabelas.values(), axis=1).reindex(columns=colunas).sort_index()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9634ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "todos = {}\n",
    "for ano in range(2000, 2022):\n",
    "    print(f'Procesando ano {ano}...', end='')\n",
    "    df = resumo_anual(ano)\n",
    "    todos[ano] = df\n",
    "    #df.to_csv(f'{ano}.csv', sep=';', decimal=',', encoding='latin_1')\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b0dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtrado = [(k, v[v.index.str.startswith(('S -- SC', 'SE -- SP'))]) for k, v in todos.items()]\n",
    "pd.DataFrame([v['PORCENTAGEM - PRECIPITAÇÃO TOTAL, HORÁRIO (mm)'].rename(k) for k, v in filtrado if not v.empty]).T.sort_index().iloc[:, 14:].applymap(lambda x: 'x' if x < 1/13*100 else '').to_csv('porcentagem.csv', sep=';', decimal=',', encoding='latin_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9529af04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c76a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
